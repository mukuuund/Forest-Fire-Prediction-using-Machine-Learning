{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "#Import All Required Libraries\n",
        "\n"
      ],
      "metadata": {
        "id": "scmKXuOv74ZC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZQbjkrD2QZd9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import warnings\n",
        "\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing Datasets"
      ],
      "metadata": {
        "id": "jV3s04AJ8BDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1=pd.read_csv('forest1.csv')\n",
        "df2=pd.read_csv('forest2.csv')"
      ],
      "metadata": {
        "id": "nPgXYe9WQlbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "31e69977-076b-4296-b193-41464d8716cb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'forest1.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1801882540.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'forest1.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'forest2.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'forest1.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Identifying the dataypes of different columns\n"
      ],
      "metadata": {
        "id": "RFT-oQ7HlSmf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1.head()"
      ],
      "metadata": {
        "id": "GmD2ubccWOs8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.info()"
      ],
      "metadata": {
        "id": "oN5RcJ-MQk7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.head()"
      ],
      "metadata": {
        "id": "WKFwxGT7QlF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.info()"
      ],
      "metadata": {
        "id": "ZRG4sBrQQkws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating a single dataset by assigning Regions"
      ],
      "metadata": {
        "id": "ByeaPaxC8WdF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1['Region'] = 1\n",
        "df1.head()"
      ],
      "metadata": {
        "id": "NncfyCNeQkmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fef976f"
      },
      "source": [
        "df2['Region'] = 2\n",
        "df2.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0f7443b"
      },
      "source": [
        "df = pd.concat([df1, df2], ignore_index=True)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "xSTDPKTlQkcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OVERALL ANALYSIS**\n",
        "\n",
        "The dataset contains **15 columns** and **244 rows**, representing meteorological and environmental observations across different regions and time periods. The data types are distributed as follows:\n",
        "\n",
        "Integer columns (7): day, month, year, Temperature, RH, Ws, and Region — these capture date information and basic weather parameters such as temperature, relative humidity, wind speed, and the region code.\n",
        "\n",
        "Float columns (5): Rain, FFMC, DMC, ISI, and BUI — these represent continuous meteorological indices used in fire weather modeling.\n",
        "\n",
        "Object columns (3): DC, FWI, and Classes — among these, DC and FWI are likely numerical values stored as text that should be converted to float, while Classes indicates the categorical fire occurrence label.\n",
        "\n",
        "Notably, the Classes column has one missing entry (243 non-null), which may require imputation or removal during preprocessing."
      ],
      "metadata": {
        "id": "ALzsDvmS8d1u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Converting to proper datatype"
      ],
      "metadata": {
        "id": "7cbdr6eUMJ8L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['DC'] = pd.to_numeric(df['DC'], errors='coerce')\n",
        "df['FWI'] = pd.to_numeric(df['FWI'], errors='coerce')"
      ],
      "metadata": {
        "id": "desuosN2MN24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "6kG5tWmPMonP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Descriptive Statistics of the Columns\n"
      ],
      "metadata": {
        "id": "Qs5u7Nb98woG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "o0GN0O9pi7bU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Identifying & Handling Missing Values"
      ],
      "metadata": {
        "id": "WTHb9itT9EXA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "missing_counts = df.isnull().sum()\n",
        "missing_percent = (missing_counts / len(df)) * 100\n",
        "\n",
        "\n",
        "missing_df = pd.DataFrame({\n",
        "    'Missing Count': missing_counts,\n",
        "    'Missing Percentage': missing_percent\n",
        "}).sort_values(by='Missing Percentage', ascending=False)\n",
        "\n",
        "missing_df"
      ],
      "metadata": {
        "id": "5TqlYcKi9GGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Since there is only one missing value in 3 features, we can safely ignore it without affecting the data much**"
      ],
      "metadata": {
        "id": "vEqswh1C9293"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(inplace=True)\n",
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "-CLH2Hk8QkSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Identifying & Handling Duplicate Values"
      ],
      "metadata": {
        "id": "AL574LoW-K6T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "duplicate_count = df.duplicated().sum()\n",
        "print(f\"Number of duplicate rows: {duplicate_count}\")\n",
        "\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "df.shape"
      ],
      "metadata": {
        "id": "xgTHwJAe-MGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Identifying columns inconsistency"
      ],
      "metadata": {
        "id": "a2yI7QKq-kIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "2IgyPBqpQkI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns=df.columns.str.strip()\n",
        "df.columns"
      ],
      "metadata": {
        "id": "X1PAJNgYQj8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in df.columns:\n",
        "    print(f\"\\n--- {col} ---\")\n",
        "    print(df[col].value_counts(dropna=False).head(10))\n"
      ],
      "metadata": {
        "id": "n8v1Cphl-5bZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Classes']=df['Classes'].str.strip()\n",
        "df['Classes']=df['Classes'].map({'fire':1,'not fire':0})\n",
        "df['Classes'].value_counts()"
      ],
      "metadata": {
        "id": "plSCam64kHsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Identifying and handling Outliers"
      ],
      "metadata": {
        "id": "w7SYbKp7AAJL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_iqr_outliers(series):\n",
        "    Q1 = series.quantile(0.25)\n",
        "    Q3 = series.quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    return ((series < lower_bound) | (series > upper_bound)).sum()\n",
        "\n",
        "outlier_counts = {col: count_iqr_outliers(df[col]) for col in df.select_dtypes(include=['number'])}\n",
        "pd.DataFrame.from_dict(outlier_counts, orient='index', columns=['Outlier Count'])"
      ],
      "metadata": {
        "id": "NqfJHghcAD2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.plot(kind='box', subplots=True, layout=(5,3), figsize=(20,15), patch_artist=True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AcOW_k24CiCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Seems there are outliers according to the IQR method. But we are not sure of it yet if we should remove these. As we have a problem with detection outliers itself i.e forest fires which happend rarely, we decided not to do anything for these outliers that we got from IQR method**"
      ],
      "metadata": {
        "id": "TNGkfM_FAh8-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Checking the Distribution of the Dataset"
      ],
      "metadata": {
        "id": "_ivRFe94D21u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.hist(bins=50, figsize=(20,15), ec = 'b')\n",
        "plt.title(\"Distibution of Dataset\",fontsize=13)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CCIs6Pmtshug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**day**: This is uniformly distributed, it itself is usually a weak predictor of forest fires (day 5 isn't inherently more dangerous than day 25). It can be dropped.\n",
        "\n",
        "**month**: This is a categorical feature with four distinct values (June, July, August, September). This is a strong and important feature as it captures the seasonal progression of fire danger (e.g., August is typically hotter and drier than June).\n",
        "\n",
        "**year**: This is a constant feature (all 2012). It has zero variance and provides no predictive information. It must be dropped.\n",
        "\n",
        "**Temperature**: This feature is normally distributed, centered around 32-35°C. This is a stable predictor for most models.\n",
        "\n",
        "**Rain**: This is highly right-skewed and zero-inflated. The vast majority of entries are 0.0 (no rain), which is typical for a fire season. The presence (Rain > 0) vs. absence (Rain = 0) of rain is likely a more powerful predictor than the specific amount.\n",
        "\n",
        "**FFMC (Fine Fuel Moisture Code)**: This is strongly left-skewed. Most values are very high (80-95), indicating that surface fuels (grass, leaves) are very dry and highly combustible on most days.\n",
        "\n",
        "**DMC (Duff Moisture Code)**: This is right-skewed. Most values are low, meaning the deeper duff layer is often moist. The long tail of high values represents extended dry periods where this deep fuel dries out, leading to more intense fires.\n",
        "\n",
        "**DC (Drought Code)**: This is highly right-skewed with a very long tail. Most values are low (0-50), indicating that severe, long-term drought is uncommon. The long tail (past 200) represents rare but critical periods of extreme drought, which would make fires much more intense and difficult to control.\n",
        "\n",
        "**ISI (Initial Spread Index)**: This is right-skewed. Similar to wind speed, most days have a low potential for fire spread, but a few days have a very high potential, which is critical to predict.\n",
        "\n",
        "**BUI (Buildup Index)**: This is right-skewed and looks similar to DMC. It represents the total fuel available for combustion and shows that while this is low on most days, it can build up significantly during dry spells.\n",
        "\n",
        "**FWI (Fire Weather Index)**: This is highly right-skewed. As the final composite index representing total fire intensity, this distribution shows that most days have a low-to-moderate fire risk (values 0-10). The long tail represents the few critical days with very high fire danger."
      ],
      "metadata": {
        "id": "eXD_WkX5Kd28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(df.corr(numeric_only=True).round(2),\n",
        "            annot=True,\n",
        "            fmt='.2f',\n",
        "            cmap='coolwarm')\n",
        "plt.title(\"Correlation Heatmap\", fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "p0HtzSHcshbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Correlation with Target (Classes)**\n",
        "**High Positive Correlation:** FFMC (0.77), ISI (0.74), FWI (0.72), DMC (0.59), and DC (0.51) all have a strong-to-moderate positive relationship. As these values go up, the chance of fire goes up.\n",
        "\n",
        "**Moderate/Low Negative Correlation:** RH (-0.43) and Rain (-0.38) have a moderate-to-low negative relationship. As these values go up (more humidity or rain), the chance of fire goes down.\n",
        "\n",
        "**Very Low / No Correlation:** Temperature (0.20), day (0.20), Region (0.16), Ws (0.07), month (0.02), year (-0.00).\n"
      ],
      "metadata": {
        "id": "fAuO_JQOJaRI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Multicollinearity (Correlation Between Predictors)**\n",
        "\n",
        "**Extremely High Correlation (Redundant):**\n",
        "\n",
        "**BUI and DMC (0.98):** Nearly identical. Can be dropped.\n",
        "\n",
        "**BUI and DC (0.94):** Nearly identical.\n",
        "\n",
        "**FWI and ISI (0.92):** FWI is heavily dependent on ISI.\n",
        "\n",
        "**DC and DMC (0.88):** Extremely high correlation.\n",
        "\n",
        "**FWI and BUI (0.86):** Extremely high correlation.\n",
        "\n",
        "**ISI and FFMC (0.74):** Very high correlation.\n",
        "\n",
        "**FWI and DC (0.74):** Very high correlation.\n",
        "\n",
        "**High-to-Moderate Correlation:**\n",
        "\n",
        "**FWI and FFMC (0.69)**\n",
        "\n",
        "**DMC and ISI (0.68)**\n",
        "\n",
        "**FFMC and RH (-0.64)**\n",
        "\n",
        "**DMC and FFMC (0.60)**"
      ],
      "metadata": {
        "id": "Ky9T8FWjKafO"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8581bf47"
      },
      "source": [
        "fire_counts_monthly = df.groupby(['Region', 'month', 'Classes']).size().unstack(fill_value=0)\n",
        "\n",
        "fire_counts_monthly.loc[1].plot(kind='bar', figsize=(10, 6))\n",
        "plt.title('Fire and Not Fire Counts by Month in Region 1')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=0)\n",
        "plt.legend(title='Classes')\n",
        "plt.show()\n",
        "\n",
        "fire_counts_monthly.loc[2].plot(kind='bar', figsize=(10, 6))\n",
        "plt.title('Fire and Not Fire Counts by Month in Region 2')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=0)\n",
        "plt.legend(title='Classes')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Months 7 and 8 seems to have more higher chances of fire**"
      ],
      "metadata": {
        "id": "CUeNYa5JQAkp"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "833f6c68"
      },
      "source": [
        "fire_counts = df.groupby(['Region', 'Classes']).size().unstack(fill_value=0)\n",
        "\n",
        "fire_counts.plot(kind='bar', figsize=(8, 6))\n",
        "plt.title('Fire and Not Fire Counts by Region')\n",
        "plt.xlabel('Region')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=0)\n",
        "plt.legend(title='Classes')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Region 2 has more fires as compared to region Region 1**"
      ],
      "metadata": {
        "id": "YppSoluBQI37"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8417d835"
      },
      "source": [
        "class_counts = df['Classes'].value_counts()\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.pie(class_counts, labels=class_counts.index, autopct='%1.1f%%')\n",
        "plt.title('Proportion of Fire and Not Fire Classes')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['day','FWI','BUI','DC','ISI','DMC','year'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "AFvnptgcEyeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Splitting dataset"
      ],
      "metadata": {
        "id": "V5G1mqtnRjB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop('Classes',axis=1)\n",
        "y= df['Classes']\n",
        "X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "rqKardnBRlyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Training"
      ],
      "metadata": {
        "id": "rcsFcvtrDt1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(random_state=42),\n",
        "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "    \"SVM Classifier\": SVC(probability=True, random_state=42),\n",
        "    \"XGBoost\": XGBClassifier(random_state=42),\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    pipeline = Pipeline(steps=[\n",
        "        ('preprocessor', StandardScaler()),\n",
        "        ('classifier', model)\n",
        "    ])\n",
        "\n",
        "    pipeline.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = pipeline.predict(X_val)\n",
        "    y_pred_proba = pipeline.predict_proba(X_val)[:, 1]\n",
        "\n",
        "    accuracy = accuracy_score(y_val, y_pred)\n",
        "    f1 = f1_score(y_val, y_pred)\n",
        "    roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
        "    precision = precision_score(y_val, y_pred)\n",
        "    recall = recall_score(y_val, y_pred)\n",
        "\n",
        "    results[name] = {\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1-Score': f1,\n",
        "        'ROC-AUC': roc_auc\n",
        "    }\n",
        "\n",
        "    print(f\"{name}\")\n",
        "    print(f\"Accuracy : {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall   : {recall:.4f}\")\n",
        "    print(f\"F1-Score : {f1:.4f}\")\n",
        "    print(f\"ROC-AUC  : {roc_auc:.4f}\\n\")\n",
        "\n",
        "results_df = pd.DataFrame(results).T.sort_values(by='F1-Score', ascending=False)\n",
        "print(\"\\nModel Performance Comparison\")\n",
        "print(results_df)\n"
      ],
      "metadata": {
        "id": "KQE5NEDKSlGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop('Classes', axis=1)\n",
        "y = df['Classes']\n",
        "\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(random_state=42),\n",
        "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "    \"SVM Classifier\": SVC(probability=True, random_state=42),\n",
        "    \"XGBoost\": XGBClassifier(random_state=42, eval_metric='logloss'), # Added eval_metric\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "cv_strategy = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)\n",
        "\n",
        "print(\"Running Cross-Validation...\")\n",
        "\n",
        "for name, model in models.items():\n",
        "\n",
        "    pipeline = Pipeline(steps=[\n",
        "        ('preprocessor', StandardScaler()),\n",
        "        ('classifier', model)\n",
        "    ])\n",
        "\n",
        "    scores = cross_val_score(pipeline, X, y, cv=cv_strategy, scoring='f1', n_jobs=-1)\n",
        "\n",
        "    results[name] = {\n",
        "        'F1-Mean': scores.mean(),\n",
        "        'F1-StdDev': scores.std()\n",
        "    }\n",
        "\n",
        "    print(f\"{name}: Mean F1-Score = {scores.mean():.4f} (StdDev = {scores.std():.4f})\")\n",
        "\n",
        "results_df = pd.DataFrame(results).T.sort_values(by='F1-Mean', ascending=False)\n",
        "print(\"\\nModel Performance Comparison (Cross-Validated)\")\n",
        "print(results_df)"
      ],
      "metadata": {
        "id": "wS--Ra1uEbMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', StandardScaler()),\n",
        "    ('classifier', RandomForestClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "final_pipeline.fit(X, y)\n",
        "\n",
        "feature_names = X.columns\n",
        "\n",
        "importances = final_pipeline.named_steps['classifier'].feature_importances_\n",
        "\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': importances\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print(importance_df)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Importance', y='Feature', data=importance_df)\n",
        "plt.title('Feature Importance (Random Forest)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jv9je6JLqQjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', StandardScaler()),\n",
        "    ('classifier', XGBClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "final_pipeline.fit(X, y)\n",
        "\n",
        "feature_names = X.columns\n",
        "\n",
        "importances = final_pipeline.named_steps['classifier'].feature_importances_\n",
        "\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': importances\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print(importance_df)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Importance', y='Feature', data=importance_df)\n",
        "plt.title('Feature Importance (Random Forest)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "a1mSbuORrFzs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}